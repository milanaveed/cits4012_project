{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32yCsRUo8H33"
      },
      "source": [
        "# 2024 CITS4012 Project\n",
        "*Make sure you change the file name with your group id.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCybYoGz8YWQ"
      },
      "source": [
        "# Readme\n",
        "*If there is something to be noted for the marker, please mention here.*\n",
        "\n",
        "*If you are planning to implement a program with Object Oriented Programming style, please put those the bottom of this ipynb file*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6po98qVA8bJD"
      },
      "source": [
        "# 1.Dataset Processing\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXzteTLV-JIy"
      },
      "source": [
        "## Install packages and load libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIm8MEKb-H9S",
        "outputId": "d7c95a58-0b95-4a58-ed71-fffb12db1093"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: skorch in c:\\users\\chaoz\\miniconda3\\envs\\cits4012\\lib\\site-packages (0.15.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\chaoz\\miniconda3\\envs\\cits4012\\lib\\site-packages (from skorch) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in c:\\users\\chaoz\\miniconda3\\envs\\cits4012\\lib\\site-packages (from skorch) (1.4.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\chaoz\\miniconda3\\envs\\cits4012\\lib\\site-packages (from skorch) (1.12.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in c:\\users\\chaoz\\miniconda3\\envs\\cits4012\\lib\\site-packages (from skorch) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in c:\\users\\chaoz\\miniconda3\\envs\\cits4012\\lib\\site-packages (from skorch) (4.66.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\chaoz\\miniconda3\\envs\\cits4012\\lib\\site-packages (from scikit-learn>=0.22.0->skorch) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\chaoz\\miniconda3\\envs\\cits4012\\lib\\site-packages (from scikit-learn>=0.22.0->skorch) (3.5.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\chaoz\\miniconda3\\envs\\cits4012\\lib\\site-packages (from tqdm>=4.14.0->skorch) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install skorch\n",
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import torch\n",
        "import gensim.downloader as api\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from skorch import NeuralNetClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhyJoBO8Dmgk"
      },
      "source": [
        "## Download and load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjUhqL1LMucW"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q PyDrive2\n",
        "from pydrive2.auth import GoogleAuth\n",
        "from pydrive2.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Code to download file into Colaboratory:\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "downloaded1 = drive.CreateFile({'id': '1nCCtN3vE6ujkZ4fRxqfO7WfONF0Le7jz'})\n",
        "downloaded1.GetContentFile('test.json')\n",
        "downloaded2 = drive.CreateFile({'id': '1TIK7kyjmUn93ppgYjLL9YgMbFF99duhl'})\n",
        "downloaded2.GetContentFile('train.json')\n",
        "downloaded3 = drive.CreateFile({'id': '1PUCSzVYiwzsHWWaiDKm4tbdlTofIcL7n'})\n",
        "downloaded3.GetContentFile('val.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qvff21Hv8zjk"
      },
      "outputs": [],
      "source": [
        "train_data = json.load(open(\"train.json\"))\n",
        "test_data = json.load(open(\"test.json\"))\n",
        "val_data = json.load(open(\"val.json\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Kt-B912cVCjM"
      },
      "outputs": [],
      "source": [
        "def create_dataframe(data):\n",
        "    # Extract data points and column names\n",
        "    records = data[\"data\"]\n",
        "    columns = data[\"columns\"]\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(records, columns=columns)\n",
        "    return df\n",
        "\n",
        "\n",
        "# Convert to Pandas data frame\n",
        "train_df = create_dataframe(train_data)\n",
        "test_df = create_dataframe(test_data)\n",
        "val_df = create_dataframe(val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlxZquj3YVm2",
        "outputId": "b37321f6-e004-444a-b184-3f6484e12482"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\chaoz\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\chaoz\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download(\"punkt\")  # Download punkt tokenizer from nltk\n",
        "nltk.download(\"stopwords\")  # Download stopwords from nltk\n",
        "\n",
        "# Assume the contraction_dict contains all the contractions\n",
        "contraction_dict = {\n",
        "    \"ain't\": \"is not\",\n",
        "    \"aren't\": \"are not\",\n",
        "    \"can't\": \"cannot\",\n",
        "    \"'cause\": \"because\",\n",
        "    \"could've\": \"could have\",\n",
        "    \"couldn't\": \"could not\",\n",
        "    \"didn't\": \"did not\",\n",
        "    \"doesn't\": \"does not\",\n",
        "    \"don't\": \"do not\",\n",
        "    \"hadn't\": \"had not\",\n",
        "    \"hasn't\": \"has not\",\n",
        "    \"haven't\": \"have not\",\n",
        "    \"he'd\": \"he would\",\n",
        "    \"he'll\": \"he will\",\n",
        "    \"he's\": \"he is\",\n",
        "    \"how'd\": \"how did\",\n",
        "    \"how'd'y\": \"how do you\",\n",
        "    \"how'll\": \"how will\",\n",
        "    \"how's\": \"how is\",\n",
        "    \"I'd\": \"I would\",\n",
        "    \"I'd've\": \"I would have\",\n",
        "    \"I'll\": \"I will\",\n",
        "    \"I'll've\": \"I will have\",\n",
        "    \"I'm\": \"I am\",\n",
        "    \"I've\": \"I have\",\n",
        "    \"i'd\": \"i would\",\n",
        "    \"i'd've\": \"i would have\",\n",
        "    \"i'll\": \"i will\",\n",
        "    \"i'll've\": \"i will have\",\n",
        "    \"i'm\": \"i am\",\n",
        "    \"i've\": \"i have\",\n",
        "    \"isn't\": \"is not\",\n",
        "    \"it'd\": \"it would\",\n",
        "    \"it'd've\": \"it would have\",\n",
        "    \"it'll\": \"it will\",\n",
        "    \"it'll've\": \"it will have\",\n",
        "    \"it's\": \"it is\",\n",
        "    \"let's\": \"let us\",\n",
        "    \"ma'am\": \"madam\",\n",
        "    \"mayn't\": \"may not\",\n",
        "    \"might've\": \"might have\",\n",
        "    \"mightn't\": \"might not\",\n",
        "    \"mightn't've\": \"might not have\",\n",
        "    \"must've\": \"must have\",\n",
        "    \"mustn't\": \"must not\",\n",
        "    \"mustn't've\": \"must not have\",\n",
        "    \"needn't\": \"need not\",\n",
        "    \"needn't've\": \"need not have\",\n",
        "    \"o'clock\": \"of the clock\",\n",
        "    \"oughtn't\": \"ought not\",\n",
        "    \"oughtn't've\": \"ought not have\",\n",
        "    \"shan't\": \"shall not\",\n",
        "    \"sha'n't\": \"shall not\",\n",
        "    \"shan't've\": \"shall not have\",\n",
        "    \"she'd\": \"she would\",\n",
        "    \"she'd've\": \"she would have\",\n",
        "    \"she'll\": \"she will\",\n",
        "    \"she'll've\": \"she will have\",\n",
        "    \"she's\": \"she is\",\n",
        "    \"should've\": \"should have\",\n",
        "    \"shouldn't\": \"should not\",\n",
        "    \"shouldn't've\": \"should not have\",\n",
        "    \"so've\": \"so have\",\n",
        "    \"so's\": \"so as\",\n",
        "    \"this's\": \"this is\",\n",
        "    \"that'd\": \"that would\",\n",
        "    \"that'd've\": \"that would have\",\n",
        "    \"that's\": \"that is\",\n",
        "    \"there'd\": \"there would\",\n",
        "    \"there'd've\": \"there would have\",\n",
        "    \"there's\": \"there is\",\n",
        "    \"here's\": \"here is\",\n",
        "    \"they'd\": \"they would\",\n",
        "    \"they'd've\": \"they would have\",\n",
        "    \"they'll\": \"they will\",\n",
        "    \"they'll've\": \"they will have\",\n",
        "    \"they're\": \"they are\",\n",
        "    \"they've\": \"they have\",\n",
        "    \"to've\": \"to have\",\n",
        "    \"wasn't\": \"was not\",\n",
        "    \"we'd\": \"we would\",\n",
        "    \"we'd've\": \"we would have\",\n",
        "    \"we'll\": \"we will\",\n",
        "    \"we'll've\": \"we will have\",\n",
        "    \"we're\": \"we are\",\n",
        "    \"we've\": \"we have\",\n",
        "    \"weren't\": \"were not\",\n",
        "    \"what'll\": \"what will\",\n",
        "    \"what'll've\": \"what will have\",\n",
        "    \"what're\": \"what are\",\n",
        "    \"what's\": \"what is\",\n",
        "    \"what've\": \"what have\",\n",
        "    \"when's\": \"when is\",\n",
        "    \"when've\": \"when have\",\n",
        "    \"where'd\": \"where did\",\n",
        "    \"where's\": \"where is\",\n",
        "    \"where've\": \"where have\",\n",
        "    \"who'll\": \"who will\",\n",
        "    \"who'll've\": \"who will have\",\n",
        "    \"who's\": \"who is\",\n",
        "    \"who've\": \"who have\",\n",
        "    \"why's\": \"why is\",\n",
        "    \"why've\": \"why have\",\n",
        "    \"will've\": \"will have\",\n",
        "    \"won't\": \"will not\",\n",
        "    \"won't've\": \"will not have\",\n",
        "    \"would've\": \"would have\",\n",
        "    \"wouldn't\": \"would not\",\n",
        "    \"wouldn't've\": \"would not have\",\n",
        "    \"y'all\": \"you all\",\n",
        "    \"y'all'd\": \"you all would\",\n",
        "    \"y'all'd've\": \"you all would have\",\n",
        "    \"y'all're\": \"you all are\",\n",
        "    \"y'all've\": \"you all have\",\n",
        "    \"you'd\": \"you would\",\n",
        "    \"you'd've\": \"you would have\",\n",
        "    \"you'll\": \"you will\",\n",
        "    \"you'll've\": \"you will have\",\n",
        "    \"you're\": \"you are\",\n",
        "    \"you've\": \"you have\",\n",
        "}\n",
        "\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))  # Load the list of stop words\n",
        "\n",
        "\n",
        "def preprocess_text(sentence):\n",
        "    # Convert into lowercase\n",
        "    sentence = sentence.lower()\n",
        "    # Convert contractions into uncontracted forms\n",
        "    for word, expanded in contraction_dict.items():\n",
        "        sentence = sentence.replace(word, expanded)\n",
        "    # Remove punctuations\n",
        "    sentence = re.sub(r\"[^\\w\\s]\", \"\", sentence)\n",
        "    # Tokenize the sentence\n",
        "    tokens = word_tokenize(sentence)\n",
        "    # Remove stop words\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    return \" \".join(filtered_tokens)  # Return the processed sentence\n",
        "\n",
        "\n",
        "def create_preprocessed_df(data):\n",
        "    # Convert into DataFrame\n",
        "    df = pd.DataFrame(data[\"data\"], columns=data[\"columns\"])\n",
        "    # Preprocess each sentence\n",
        "    df[\"processed_sentence\"] = df[\"sentence\"].apply(preprocess_text)\n",
        "    return df\n",
        "\n",
        "\n",
        "# Create and preprocess data frame\n",
        "train_df = create_preprocessed_df(train_data)\n",
        "test_df = create_preprocessed_df(test_data)\n",
        "val_df = create_preprocessed_df(val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeZBfUQIv7yq",
        "outputId": "90444ab8-686e-4fa4-83ea-4b08e9793c63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def calculate_max_length(df):\n",
        "    # Calculate the length of each tokenised sentence\n",
        "    df[\"sentence_length\"] = df[\"processed_sentence\"].apply(\n",
        "        lambda x: len(word_tokenize(x))\n",
        "    )\n",
        "    # Get the maximum length\n",
        "    max_length = df[\"sentence_length\"].max()\n",
        "    return max_length\n",
        "\n",
        "\n",
        "# Calculate the maximum length of each dataset\n",
        "max_length_train = calculate_max_length(train_df)\n",
        "max_length_test = calculate_max_length(test_df)\n",
        "max_length_val = calculate_max_length(val_df)\n",
        "\n",
        "# Get the maximum length among those three datasets\n",
        "max_length = max([max_length_train, max_length_test, max_length_val])\n",
        "max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VoiEOZsbyfIB"
      },
      "outputs": [],
      "source": [
        "def pad_sentences(sentences, max_length, pad_token=\"[PAD]\"):\n",
        "    padded_sentences = []\n",
        "    for sentence in sentences:\n",
        "        # Split sentences into words by spaces\n",
        "        words = sentence.split()\n",
        "        if len(words) > max_length:\n",
        "            # Truncate to maximum length\n",
        "            padded_sentence = words[:max_length]\n",
        "        else:\n",
        "            # Padding to maximum length\n",
        "            padded_sentence = words + [pad_token] * (max_length - len(words))\n",
        "        padded_sentences.append(\" \".join(padded_sentence))\n",
        "    return padded_sentences\n",
        "\n",
        "\n",
        "# Apply padding to each dataset\n",
        "train_df[\"padded_sentence\"] = pad_sentences(\n",
        "    train_df[\"processed_sentence\"], max_length)\n",
        "test_df[\"padded_sentence\"] = pad_sentences(\n",
        "    test_df[\"processed_sentence\"], max_length)\n",
        "val_df[\"padded_sentence\"] = pad_sentences(\n",
        "    val_df[\"processed_sentence\"], max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd2Kin2c8ER1",
        "outputId": "3f314305-8f92-414c-dd08-7d2708fd2649"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ],
      "source": [
        "# # Download and load the pretrained Word2Vec model\n",
        "# word2vec_vectors = api.load(\"word2vec-google-news-300\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# word2vec_Model.save(\"word2vec_vectors.bin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If run locally\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "word2vec_vectors = KeyedVectors.load(\"word2vec_vectors.bin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Xh2Gnlk1C9z6"
      },
      "outputs": [],
      "source": [
        "def sentence_to_avg_vector(sentence, model):\n",
        "    # Initialize a list of zero vectors to store vectors\n",
        "    vectors = []\n",
        "    for word in sentence:\n",
        "        if word in model:\n",
        "            vectors.append(model[word])\n",
        "        else:\n",
        "            # Use all-zero vectors to replace words that do not exist in the model\n",
        "            vectors.append(np.zeros(model.vector_size))\n",
        "\n",
        "    # Calculate the average of a vector\n",
        "    if vectors:\n",
        "        return np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        return np.zeros(model.vector_size)\n",
        "\n",
        "\n",
        "def process_data_frame(df, model):\n",
        "    # Tokenize sentence\n",
        "    df[\"tokenized_sentence\"] = df[\"processed_sentence\"].apply(str.split)\n",
        "\n",
        "    # Convert each sentence to its vector representation\n",
        "    df[\"sentence_vector\"] = df[\"tokenized_sentence\"].apply(\n",
        "        lambda x: sentence_to_avg_vector(x, model)\n",
        "    )\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# Apply the function to each sentence\n",
        "train_df = process_data_frame(train_df, word2vec_vectors)\n",
        "test_df = process_data_frame(test_df, word2vec_vectors)\n",
        "val_df = process_data_frame(val_df, word2vec_vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBiBqrjRaQJp"
      },
      "source": [
        "## Model 1 data processing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-nKyAy2c_mh"
      },
      "source": [
        "Use Word2vec to produce word embeddings and concatenate the aspect representation and the sentence representation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "CBxPpQRnaVIZ"
      },
      "outputs": [],
      "source": [
        "def aspect_to_vector(aspect, model):\n",
        "    if aspect in model:\n",
        "        return model[aspect]\n",
        "    else:\n",
        "        return np.zeros(model.vector_size)\n",
        "\n",
        "\n",
        "def process_data(df, model):\n",
        "    # For each aspect word in the DataFrame, obtain its vector representation\n",
        "    df[\"aspect_vector\"] = df[\"aspect\"].apply(lambda x: aspect_to_vector(x, model))\n",
        "\n",
        "    # Concatenate aspect representation and sentence representation (placing the aspect vector at the front)\n",
        "    df[\"combined_vector_ahead\"] = df.apply(\n",
        "        lambda row: np.concatenate((row[\"aspect_vector\"], row[\"sentence_vector\"])),\n",
        "        axis=1,\n",
        "    )\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "train_df = process_data(train_df, word2vec_vectors)\n",
        "test_df = process_data(test_df, word2vec_vectors)\n",
        "val_df = process_data(val_df, word2vec_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VwhHPn1FQi4b"
      },
      "outputs": [],
      "source": [
        "# Training data and labels\n",
        "X_train_model1 = np.array(list(train_df[\"combined_vector_ahead\"]))\n",
        "y_train_model1 = train_df[\"polarity\"]\n",
        "\n",
        "# Validation data and labels\n",
        "X_val_model1 = np.array(list(val_df[\"combined_vector_ahead\"]))\n",
        "y_val_model1 = val_df[\"polarity\"]\n",
        "\n",
        "# Test data and labels\n",
        "X_test_model1 = np.array(list(test_df[\"combined_vector_ahead\"]))\n",
        "y_test_model1 = test_df[\"polarity\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lsdCHTMuGhkA"
      },
      "outputs": [],
      "source": [
        "# Convert polarity information into indices (using one-hot encoding)\n",
        "label_mapping = {\"neutral\": 0, \"positive\": 1, \"negative\": 2}\n",
        "train_df[\"polarity\"] = train_df[\"polarity\"].map(label_mapping).fillna(-1).astype(int)\n",
        "val_df[\"polarity\"] = val_df[\"polarity\"].map(label_mapping).fillna(-1).astype(int)\n",
        "test_df[\"polarity\"] = test_df[\"polarity\"].map(label_mapping).fillna(-1).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XnFMGoKz4qkI"
      },
      "outputs": [],
      "source": [
        "# Get the one-hot representation of the target variable\n",
        "y_train_encoded = train_df[\"polarity\"]\n",
        "y_val_encoded = val_df[\"polarity\"]\n",
        "y_test_encoded = test_df[\"polarity\"]\n",
        "\n",
        "# Convert to PyTorch tensor\n",
        "y_train_t = torch.tensor(y_train_encoded, dtype=torch.long)\n",
        "y_val_t = torch.tensor(y_val_encoded, dtype=torch.long)\n",
        "y_test_t = torch.tensor(y_test_encoded, dtype=torch.long)\n",
        "\n",
        "# Convert to PyTorch tensor\n",
        "X_train_t = torch.tensor(X_train_model1, dtype=torch.float32).unsqueeze(1)\n",
        "X_val_t = torch.tensor(X_val_model1, dtype=torch.float32).unsqueeze(1)\n",
        "X_test_t = torch.tensor(X_test_model1, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "# Create data loader\n",
        "train_loader = DataLoader(\n",
        "    TensorDataset(X_train_t, y_train_t), batch_size=64, shuffle=True\n",
        ")\n",
        "val_loader = DataLoader(TensorDataset(X_val_t, y_val_t), batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(\n",
        "    TensorDataset(X_test_t, y_test_t), batch_size=64, shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeXWARP8TrPV"
      },
      "source": [
        "## Model 2 and Model 3 data processing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMO6drGVhyka"
      },
      "source": [
        "model2 and model3 we need to use 'padded_sentence', 'aspect' and 'polarity' separately"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJ82kXw1702u"
      },
      "outputs": [],
      "source": [
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, dataframe, word2vec_vectors, embedding_dim):\n",
        "        # Convert sentences into embedding matrices\n",
        "        self.sentences = [\n",
        "            self.text_to_vec_list(text, word2vec_vectors, embedding_dim)\n",
        "            for text in dataframe[\"padded_sentence\"]\n",
        "        ]\n",
        "        # Convert level words to embedding vectors\n",
        "        self.aspects = [\n",
        "            self.word_to_vec(aspect, word2vec_vectors, embedding_dim)\n",
        "            for aspect in dataframe[\"aspect\"]\n",
        "        ]\n",
        "        # Make sure the label is a long integer tensor\n",
        "        self.labels = torch.tensor(dataframe[\"polarity\"].values, dtype=torch.long)\n",
        "\n",
        "    def text_to_vec_list(self, text, word2vec_vectors, embedding_dim):\n",
        "        # Convert each word into a pretrained embedding vector\n",
        "        def word_to_vec(word):\n",
        "            if word in word2vec_vectors:\n",
        "                return torch.tensor(word2vec_vectors[word], dtype=torch.float)\n",
        "            else:\n",
        "                # For words not found, return a zero vector\n",
        "                return torch.zeros(embedding_dim)\n",
        "\n",
        "        # Split sentences and construct embedding matrix\n",
        "        tokens = text.split()\n",
        "        return torch.stack([word_to_vec(token) for token in tokens])\n",
        "\n",
        "    def word_to_vec(self, word, word2vec_vectors, embedding_dim):\n",
        "        # Convert level words to embedding vectors\n",
        "        if word in word2vec_vectors:\n",
        "            return torch.tensor(word2vec_vectors[word], dtype=torch.float)\n",
        "        else:\n",
        "            return torch.zeros(embedding_dim)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Return sentence embedding matrix, level word embedding vector and label\n",
        "        return self.sentences[idx], self.aspects[idx], self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qD9JGMZ1L00k"
      },
      "outputs": [],
      "source": [
        "# Define pretrained embedding model and embedding dimensions\n",
        "embedding_dim = word2vec_vectors.vector_size\n",
        "\n",
        "# Create three data sets\n",
        "train_dataset = SentimentDataset(train_df, word2vec_vectors, embedding_dim)\n",
        "val_dataset = SentimentDataset(val_df, word2vec_vectors, embedding_dim)\n",
        "test_dataset = SentimentDataset(test_df, word2vec_vectors, embedding_dim)\n",
        "\n",
        "# Create data loaders for each dataset\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T34gZQ2BeIWy"
      },
      "source": [
        "## Word representation comparison (Word2vec VS GloVe)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUJ4DaSkfdga"
      },
      "source": [
        "### GloVe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YDE6cmVNH9i",
        "outputId": "aff9864e-94c4-49a9-def9-736badca9f2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 387.1/387.1MB downloaded\n",
            "[==================================================] 100.0% 758.5/758.5MB downloaded\n"
          ]
        }
      ],
      "source": [
        "def build_vocab(sentences):\n",
        "    word_count = Counter(word for sentence in sentences for word in sentence.split())\n",
        "    vocab = [\"<PAD>\"] + sorted(word_count)\n",
        "    word_to_index = {word: idx for idx, word in enumerate(vocab)}\n",
        "    return vocab, word_to_index\n",
        "\n",
        "\n",
        "def text_to_indices(sentences, word_to_index, max_len):\n",
        "    indices = []\n",
        "    for sentence in sentences:\n",
        "        sentence_indices = [\n",
        "            word_to_index.get(word, word_to_index[\"<PAD>\"]) for word in sentence.split()\n",
        "        ]\n",
        "        padded_indices = sentence_indices + [word_to_index[\"<PAD>\"]] * (\n",
        "            max_len - len(sentence_indices)\n",
        "        )\n",
        "        indices.append(padded_indices[:max_len])\n",
        "    return indices\n",
        "\n",
        "\n",
        "all_sentences = (\n",
        "    train_df[\"processed_sentence\"].tolist()\n",
        "    + test_df[\"processed_sentence\"].tolist()\n",
        "    + val_df[\"processed_sentence\"].tolist()\n",
        ")\n",
        "vocab, word_to_index = build_vocab(all_sentences)\n",
        "max_length = 40\n",
        "\n",
        "train_indices = text_to_indices(\n",
        "    train_df[\"processed_sentence\"], word_to_index, max_length\n",
        ")\n",
        "test_indices = text_to_indices(test_df[\"processed_sentence\"], word_to_index, max_length)\n",
        "val_indices = text_to_indices(val_df[\"processed_sentence\"], word_to_index, max_length)\n",
        "\n",
        "# Convert labels to integers\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(train_df[\"polarity\"].tolist())\n",
        "y_test_encoded = label_encoder.transform(test_df[\"polarity\"].tolist())\n",
        "y_val_encoded = label_encoder.transform(val_df[\"polarity\"].tolist())\n",
        "\n",
        "# Create tensor\n",
        "train_indices_tensor = torch.tensor(train_indices, dtype=torch.long)\n",
        "test_indices_tensor = torch.tensor(test_indices, dtype=torch.long)\n",
        "val_indices_tensor = torch.tensor(val_indices, dtype=torch.long)\n",
        "train_labels_tensor = torch.tensor(y_train_encoded, dtype=torch.long)\n",
        "test_labels_tensor = torch.tensor(y_test_encoded, dtype=torch.long)\n",
        "val_labels_tensor = torch.tensor(y_val_encoded, dtype=torch.long)\n",
        "\n",
        "train_dataset = TensorDataset(train_indices_tensor, train_labels_tensor)\n",
        "test_dataset = TensorDataset(test_indices_tensor, test_labels_tensor)\n",
        "val_dataset = TensorDataset(val_indices_tensor, val_labels_tensor)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Create data loader\n",
        "word_emb_model = api.load(\"glove-twitter-100\")\n",
        "word_emb_model2 = api.load(\"glove-twitter-200\")\n",
        "emb_dim = word_emb_model.vector_size + word_emb_model2.vector_size\n",
        "emb_table = np.zeros((len(vocab), emb_dim))\n",
        "for i, word in enumerate(vocab):\n",
        "    if word in word_emb_model and word in word_emb_model2:\n",
        "        emb_table[i] = np.concatenate((word_emb_model[word], word_emb_model2[word]))\n",
        "    elif word in word_emb_model:\n",
        "        emb_table[i, : word_emb_model.vector_size] = word_emb_model[word]\n",
        "    elif word in word_emb_model2:\n",
        "        emb_table[i, word_emb_model.vector_size :] = word_emb_model2[word]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FA2ao2l8hOg"
      },
      "source": [
        "# 2.Model Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtkfKuUi3ARD"
      },
      "source": [
        "## Model 1 - Baseline BiLSTM1\n",
        "Aspect representation is concatenated and placed at the front of input layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "p1gLf7sSnw9b"
      },
      "outputs": [],
      "source": [
        "class Model1(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=2, dropout=0.5):\n",
        "        super(Model1, self).__init__()\n",
        "        # Bi-directional LSTM layer definition:\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_dim,\n",
        "            hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=dropout,\n",
        "        )\n",
        "\n",
        "        # Fully connected layer that projects from hidden state space to output space\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "\n",
        "        # Get the last time-step output from all sequences in the batch\n",
        "        polarity_space = self.fc(self.dropout(lstm_out[:, -1, :]))\n",
        "        return F.softmax(polarity_space, dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeHT7CFB27pO"
      },
      "source": [
        "## Model 2 - Baseline BiLSTM2\n",
        "Aspect representation is concatenated in the hidden layer and placed at the end."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qudI8EuNC4M"
      },
      "outputs": [],
      "source": [
        "class Model2(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=2, dropout=0.5):\n",
        "        super(Model2, self).__init__()\n",
        "        # Bi-directional LSTM layer definition:\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_dim,\n",
        "            hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=dropout,\n",
        "        )\n",
        "\n",
        "        # Fully connected layer that projects from hidden state space to output space\n",
        "        self.fc = nn.Linear(hidden_dim * 2 + input_dim, output_dim)\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, sentence_embeddings, aspect_embeddings):\n",
        "        # Generate initial sentence representation using LSTM\n",
        "        lstm_out, _ = self.lstm(sentence_embeddings)\n",
        "        lstm_out_mean = torch.mean(\n",
        "            lstm_out, dim=1\n",
        "        )  # Average pooling to obtain the representation of the entire sentence\n",
        "\n",
        "        # Concatenating LSTM outputs and aspect embeddings\n",
        "        combined_representation = torch.cat((lstm_out_mean, aspect_embeddings), dim=1)\n",
        "\n",
        "        # Fully connected layer for classification\n",
        "        polarity_space = self.fc(self.dropout(combined_representation))\n",
        "        return F.softmax(polarity_space, dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BL0nX2to7iYs"
      },
      "source": [
        "## model3 implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qevpA7r7hti"
      },
      "outputs": [],
      "source": [
        "class Model3(nn.Module):\n",
        "    def __init__(\n",
        "        self, input_dim, aspect_dim, hidden_dim, output_dim, num_layers=1, dropout=0.1\n",
        "    ):\n",
        "        super(Model3, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # BiLSTM\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_dim + aspect_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout,\n",
        "            bidirectional=False,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Attention layer parameters\n",
        "        self.w = nn.Linear(hidden_dim + aspect_dim, 1)\n",
        "\n",
        "        # final projection layer\n",
        "        self.Wp = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.Wx = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "        # Classifier\n",
        "        self.classifier = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, sentences, aspects):\n",
        "        # Extend level word embeddings to dimensions matching sentences\n",
        "        aspects_expanded = aspects.unsqueeze(1).expand(-1, sentences.size(1), -1)\n",
        "\n",
        "        # Concatenate level word embeddings with each word vector\n",
        "        lstm_input = torch.cat((sentences, aspects_expanded), dim=2)\n",
        "\n",
        "        # LSTM output\n",
        "        lstm_out, _ = self.lstm(lstm_input)\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "\n",
        "        # attention mechanism\n",
        "        M = torch.tanh(torch.cat((lstm_out, aspects_expanded), dim=2))\n",
        "        attention_weights = F.softmax(self.w(M), dim=1)\n",
        "        attention_weights = attention_weights.transpose(1, 2)\n",
        "\n",
        "        # weighted representation\n",
        "        r = torch.bmm(attention_weights, lstm_out).squeeze(1)\n",
        "\n",
        "        # The final expression of the combination\n",
        "        h_star = torch.tanh(self.Wp(r) + self.Wx(lstm_out[:, -1, :]))\n",
        "\n",
        "        # Classification output\n",
        "        output = self.classifier(h_star)\n",
        "        return F.log_softmax(output, dim=-1), attention_weights\n",
        "        # return F.softmax(output, dim=-1), attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxNEEPb8fB-6"
      },
      "source": [
        "## model4 implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMwwwiAzf_wF"
      },
      "source": [
        "### glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBRihDB9fGqq"
      },
      "outputs": [],
      "source": [
        "class BiLSTMClassifier(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, output_dim, emb_table):\n",
        "        super(BiLSTMClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(emb_table))\n",
        "        self.embedding.weight.requires_grad = False\n",
        "        self.lstm = nn.LSTM(\n",
        "            embedding_dim,\n",
        "            hidden_dim,\n",
        "            num_layers=1,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x, _ = self.lstm(x)\n",
        "        x = self.fc(x[:, -1, :])\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzGuzHPE87Ya"
      },
      "source": [
        "# 3.Testing and Evaluation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WW_2v7Q26-eO"
      },
      "source": [
        "## Model 1 - Baseline BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq2IHgsT7Ych",
        "outputId": "a0b97143-6fc0-4781-8c35-17a3113b7a13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Train Loss = 0.9796, Train Accuracy: 0.5704\n",
            "Epoch [2/10], Train Loss = 0.9090, Train Accuracy: 0.6324\n",
            "Epoch [3/10], Train Loss = 0.8952, Train Accuracy: 0.6443\n",
            "Epoch [4/10], Train Loss = 0.8872, Train Accuracy: 0.6542\n",
            "Epoch [5/10], Train Loss = 0.8842, Train Accuracy: 0.6515\n",
            "Epoch [6/10], Train Loss = 0.8781, Train Accuracy: 0.6643\n",
            "Epoch [7/10], Train Loss = 0.8727, Train Accuracy: 0.6680\n",
            "Epoch [8/10], Train Loss = 0.8724, Train Accuracy: 0.6683\n",
            "Epoch [9/10], Train Loss = 0.8692, Train Accuracy: 0.6717\n",
            "Epoch [10/10], Train Loss = 0.8647, Train Accuracy: 0.6777\n",
            "Test Accuracy: 0.6537, Test Macro-F1: 0.6165\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model1 = Model1(\n",
        "    input_dim=X_train_t.shape[2],\n",
        "    hidden_dim=128,\n",
        "    output_dim=3,\n",
        "    num_layers=2,\n",
        "    dropout=0.5,\n",
        ").to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model1.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        all_predictions = []\n",
        "        all_labels = []\n",
        "\n",
        "        for data, targets in train_loader:\n",
        "            # Move data to GPU or CPU\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "\n",
        "            # Clear gradient\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward propagation\n",
        "            outputs = model(data)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(outputs, targets)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Backpropagate and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Record predictions and labels\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(targets.cpu().numpy())\n",
        "\n",
        "        # Training set accuracy and loss\n",
        "        train_accuracy = accuracy_score(all_labels, all_predictions)\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "        print(\n",
        "            f\"Epoch [{epoch+1}/{num_epochs}], Train Loss = {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\"\n",
        "        )\n",
        "\n",
        "\n",
        "train_model(model1, train_loader, criterion, optimizer)\n",
        "\n",
        "\n",
        "def evaluate_model(model, data_loader):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for data, labels in data_loader:\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "            outputs = model(data)\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    test_accuracy = accuracy_score(all_labels, all_preds)\n",
        "    macro_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f}, Test Macro-F1: {macro_f1:.4f}\")\n",
        "\n",
        "\n",
        "evaluate_model(model1, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQDKQwFlrquk",
        "outputId": "57803342-ff95-4259-b7be-b4486aafff81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n"
          ]
        }
      ],
      "source": [
        "model = NeuralNetClassifier(\n",
        "    Model1,\n",
        "    module__input_dim=X_train_t.shape[2],\n",
        "    module__hidden_dim=128,\n",
        "    module__output_dim=3,\n",
        "    module__num_layers=2,\n",
        "    module__dropout=0.5,\n",
        "    criterion=nn.CrossEntropyLoss(),\n",
        "    max_epochs=10,\n",
        "    batch_size=64,\n",
        "    optimizer=optim.Adagrad,\n",
        "    optimizer__lr=0.01,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    # 'module__dropout_rate': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
        "    # 'optimizer': [optim.SGD, optim.RMSprop, optim.Adagrad, optim.Adadelta,\n",
        "    #   optim.Adam, optim.Adamax, optim.NAdam],  #optim.Adagrad\n",
        "    # 'optimizer__lr': [0.00001, 0.0001,0.001, 0.01, 0.1], # 0.01\n",
        "    # \"batch_size\": [16, 32, 64, 128, 256], #64\n",
        "    # \"max_epochs\": [10, 30, 50, 70, 100],\n",
        "    \"module__hidden_dim\": [64, 128, 256, 512]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=10, verbose=3)\n",
        "grid_result = grid.fit(X_val_t, y_val_t)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_[\"mean_test_score\"]\n",
        "stds = grid_result.cv_results_[\"std_test_score\"]\n",
        "params = grid_result.cv_results_[\"params\"]\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"Mean Validation Accuracy %.4f (%.4f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVmagbbp3ara"
      },
      "source": [
        "## model2 testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_Pog15t4kcy",
        "outputId": "72c7cb1a-091d-462e-c0c1-3307572790eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Train Loss: 0.9828, Train Accuracy: 0.5614, Val Loss: 0.9314, Val Accuracy: 0.6149\n",
            "Epoch [2/10], Train Loss: 0.9291, Train Accuracy: 0.6151, Val Loss: 0.9191, Val Accuracy: 0.6149\n",
            "Epoch [3/10], Train Loss: 0.9138, Train Accuracy: 0.6291, Val Loss: 0.9000, Val Accuracy: 0.6318\n",
            "Epoch [4/10], Train Loss: 0.9035, Train Accuracy: 0.6399, Val Loss: 0.9169, Val Accuracy: 0.6182\n",
            "Epoch [5/10], Train Loss: 0.9027, Train Accuracy: 0.6401, Val Loss: 0.9077, Val Accuracy: 0.6284\n",
            "Epoch [6/10], Train Loss: 0.9003, Train Accuracy: 0.6413, Val Loss: 0.8972, Val Accuracy: 0.6306\n",
            "Epoch [7/10], Train Loss: 0.8990, Train Accuracy: 0.6439, Val Loss: 0.8988, Val Accuracy: 0.6261\n",
            "Epoch [8/10], Train Loss: 0.8915, Train Accuracy: 0.6471, Val Loss: 0.8943, Val Accuracy: 0.6408\n",
            "Epoch [9/10], Train Loss: 0.8829, Train Accuracy: 0.6626, Val Loss: 0.8876, Val Accuracy: 0.6588\n",
            "Epoch [10/10], Train Loss: 0.9295, Train Accuracy: 0.6147, Val Loss: 0.9177, Val Accuracy: 0.6160\n",
            "Test Loss: 0.9129, Test Accuracy: 0.6215\n"
          ]
        }
      ],
      "source": [
        "embedding_dim = 300\n",
        "hidden_dim = 128\n",
        "output_dim = 3\n",
        "num_layers = 2\n",
        "dropout = 0.5\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "\n",
        "# Instantiate the model\n",
        "model2 = Model2(embedding_dim, hidden_dim, output_dim, num_layers, dropout)\n",
        "\n",
        "# Loss functions and optimizers\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model2.parameters(), lr=learning_rate)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model2 = model2.to(device)\n",
        "\n",
        "\n",
        "# Evaluation function: returns loss and accuracy\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for sentences, aspects, labels in dataloader:\n",
        "            sentences = sentences.to(device)\n",
        "            aspects = aspects.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(sentences, aspects)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "\n",
        "# Training and validation functions\n",
        "def train_and_evaluate(\n",
        "    model, train_loader, val_loader, criterion, optimizer, num_epochs, device\n",
        "):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        all_predictions = []\n",
        "        all_labels = []\n",
        "\n",
        "        for sentence_embeddings, aspect_embeddings, labels in train_loader:\n",
        "            # Move data to GPU or CPU\n",
        "            sentence_embeddings = sentence_embeddings.to(device)\n",
        "            aspect_embeddings = aspect_embeddings.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Clear gradient\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward propagation\n",
        "            outputs = model(sentence_embeddings, aspect_embeddings)\n",
        "\n",
        "            # Calculate losses\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Backpropagate and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Record predictions and labels\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Training set accuracy\n",
        "        train_accuracy = accuracy_score(all_labels, all_predictions)\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "        # Validation set evaluation\n",
        "        val_loss, val_accuracy = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "        # Output loss and accuracy for training and validation\n",
        "        print(\n",
        "            f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
        "            f\"Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n",
        "            f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\"\n",
        "        )\n",
        "\n",
        "\n",
        "train_and_evaluate(\n",
        "    model2, train_loader, val_loader, criterion, optimizer, num_epochs, device\n",
        ")\n",
        "\n",
        "# After training, evaluate on the test set\n",
        "test_loss, test_accuracy = evaluate(model2, test_loader, criterion, device)\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsnY6r8X7oFS"
      },
      "source": [
        "## model3 testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3m0RRD84-11",
        "outputId": "301dbbcf-49d3-43d5-d605-24d2f5a0bfc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: Train Loss = 0.8998, Val Loss = 0.8196, Val Accuracy = 0.6115\n",
            "Epoch 2/10: Train Loss = 0.8229, Val Loss = 0.7745, Val Accuracy = 0.6475\n",
            "Epoch 3/10: Train Loss = 0.7737, Val Loss = 0.7428, Val Accuracy = 0.6734\n",
            "Epoch 4/10: Train Loss = 0.7272, Val Loss = 0.6986, Val Accuracy = 0.7106\n",
            "Epoch 5/10: Train Loss = 0.6796, Val Loss = 0.7041, Val Accuracy = 0.6836\n",
            "Epoch 6/10: Train Loss = 0.6388, Val Loss = 0.6791, Val Accuracy = 0.7207\n",
            "Epoch 7/10: Train Loss = 0.5988, Val Loss = 0.6968, Val Accuracy = 0.7173\n",
            "Epoch 8/10: Train Loss = 0.5636, Val Loss = 0.6608, Val Accuracy = 0.7241\n",
            "Epoch 9/10: Train Loss = 0.5180, Val Loss = 0.6837, Val Accuracy = 0.7162\n",
            "Epoch 10/10: Train Loss = 0.4779, Val Loss = 0.6691, Val Accuracy = 0.7342\n",
            "Test Loss = 0.7069, Test Accuracy = 0.7114\n"
          ]
        }
      ],
      "source": [
        "input_dim = 300\n",
        "aspect_dim = 300\n",
        "hidden_dim = 128\n",
        "output_dim = 3\n",
        "num_layers = 1\n",
        "dropout_p = 0.2\n",
        "\n",
        "\n",
        "model3 = Model3(input_dim, aspect_dim, hidden_dim, output_dim, num_layers, dropout_p)\n",
        "\n",
        "\n",
        "# Loss functions and optimizers\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model3.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "# training function\n",
        "def train(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for sentences, aspects, labels in dataloader:\n",
        "        sentences, aspects, labels = (\n",
        "            sentences.to(device),\n",
        "            aspects.to(device),\n",
        "            labels.to(device),\n",
        "        )\n",
        "        optimizer.zero_grad()\n",
        "        outputs, _ = model(sentences, aspects)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "\n",
        "# Verification function\n",
        "def validate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for sentences, aspects, labels in dataloader:\n",
        "            sentences, aspects, labels = (\n",
        "                sentences.to(device),\n",
        "                aspects.to(device),\n",
        "                labels.to(device),\n",
        "            )\n",
        "            outputs, _ = model(sentences, aspects)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct_predictions += (preds == labels).sum().item()\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    accuracy = correct_predictions / len(dataloader.dataset)\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "\n",
        "# Train and validate models\n",
        "num_epochs = 10\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model3.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train(model3, train_loader, criterion, optimizer, device)\n",
        "    val_loss, val_accuracy = validate(model3, val_loader, criterion, device)\n",
        "    print(\n",
        "        f\"Epoch {epoch+1}/{num_epochs}: \"\n",
        "        f\"Train Loss = {train_loss:.4f}, \"\n",
        "        f\"Val Loss = {val_loss:.4f}, Val Accuracy = {val_accuracy:.4f}\"\n",
        "    )\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_loss, test_accuracy = validate(model3, test_loader, criterion, device)\n",
        "print(f\"Test Loss = {test_loss:.4f}, Test Accuracy = {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlK6Xad1mVuI"
      },
      "source": [
        "### Visual attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "mjBywDmdmisn",
        "outputId": "9b8e69ea-2dde-49d5-b545-2bffd6da5ba2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x200 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model3.to(device)\n",
        "\n",
        "\n",
        "# Function to visualize attention weights\n",
        "def visualize_attention(sentence, aspect, attention_weights):\n",
        "    \"\"\"\n",
        "    Visualize attention weights as heat maps.\n",
        "    :param sentence: Input sentences (list)\n",
        "    :param aspect: aspect words\n",
        "    :param attention_weights: attention weight (tensor)\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(20, 2))\n",
        "    sns.heatmap(\n",
        "        attention_weights,\n",
        "        annot=True,\n",
        "        fmt=\".2f\",\n",
        "        xticklabels=sentence,\n",
        "        yticklabels=[aspect],\n",
        "        cmap=\"Reds\",\n",
        "    )\n",
        "    plt.xlabel(\"Sentence Tokens\")\n",
        "    plt.ylabel(\"Aspect\")\n",
        "    plt.title(\"Attention Visualization\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "target_index = 0\n",
        "\n",
        "\n",
        "model3.eval()\n",
        "with torch.no_grad():\n",
        "    sentences, aspects = None, None\n",
        "    current_index = 0\n",
        "    for batch_sentences, batch_aspects, _ in test_loader:\n",
        "        batch_size = batch_sentences.size(0)\n",
        "        if current_index <= target_index < current_index + batch_size:\n",
        "            relative_index = target_index - current_index\n",
        "            sentences = batch_sentences[relative_index].unsqueeze(0).to(device)\n",
        "            aspects = batch_aspects[relative_index].unsqueeze(0).to(device)\n",
        "            break\n",
        "        current_index += batch_size\n",
        "\n",
        "    # Get the attention weight from the model\n",
        "    _, attention_weights = model3(sentences, aspects)\n",
        "\n",
        "    # Get `tokenized_sentence` and `aspect` from `test_df`\n",
        "    sentence_example = test_df[\"tokenized_sentence\"][target_index]\n",
        "    aspect_example = test_df[\"aspect\"][target_index]\n",
        "\n",
        "    visualize_attention(\n",
        "        sentence_example, aspect_example, attention_weights[0].cpu().numpy()\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekURaEwApv_v"
      },
      "source": [
        "## model4 testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfJSzwEFqcuv"
      },
      "source": [
        "### glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsVmSkK2q8Hl",
        "outputId": "de0040b2-7141-4c6e-be43-7ed713c216e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/100], Loss: 1.0780, Train Accuracy: 0.4289\n",
            "Test Accuracy: 0.4362\n",
            "Epoch [2/100], Loss: 1.0773, Train Accuracy: 0.4344\n",
            "Test Accuracy: 0.4362\n",
            "Epoch [3/100], Loss: 1.0765, Train Accuracy: 0.4343\n",
            "Test Accuracy: 0.4362\n",
            "Epoch [4/100], Loss: 1.0764, Train Accuracy: 0.4343\n",
            "Test Accuracy: 0.4362\n",
            "Epoch [5/100], Loss: 1.0768, Train Accuracy: 0.4344\n",
            "Test Accuracy: 0.4362\n",
            "Epoch [6/100], Loss: 1.0762, Train Accuracy: 0.4343\n",
            "Test Accuracy: 0.4362\n",
            "Epoch [7/100], Loss: 1.0745, Train Accuracy: 0.4339\n",
            "Test Accuracy: 0.4340\n",
            "Epoch [8/100], Loss: 1.0754, Train Accuracy: 0.4336\n",
            "Test Accuracy: 0.4362\n",
            "Epoch [9/100], Loss: 1.0764, Train Accuracy: 0.4341\n",
            "Test Accuracy: 0.4362\n",
            "Epoch [10/100], Loss: 1.0706, Train Accuracy: 0.4344\n",
            "Test Accuracy: 0.4340\n",
            "Epoch [11/100], Loss: 1.0422, Train Accuracy: 0.4258\n",
            "Test Accuracy: 0.4562\n",
            "Epoch [12/100], Loss: 1.0208, Train Accuracy: 0.4437\n",
            "Test Accuracy: 0.4462\n",
            "Epoch [13/100], Loss: 1.0035, Train Accuracy: 0.4528\n",
            "Test Accuracy: 0.4573\n",
            "Epoch [14/100], Loss: 0.9919, Train Accuracy: 0.4590\n",
            "Test Accuracy: 0.4362\n",
            "Epoch [15/100], Loss: 0.9748, Train Accuracy: 0.4554\n",
            "Test Accuracy: 0.4584\n",
            "Epoch [16/100], Loss: 0.9548, Train Accuracy: 0.4591\n",
            "Test Accuracy: 0.4639\n",
            "Epoch [17/100], Loss: 0.9351, Train Accuracy: 0.4638\n",
            "Test Accuracy: 0.4451\n",
            "Epoch [18/100], Loss: 0.9231, Train Accuracy: 0.4674\n",
            "Test Accuracy: 0.4650\n",
            "Epoch [19/100], Loss: 0.9169, Train Accuracy: 0.4671\n",
            "Test Accuracy: 0.4606\n",
            "Epoch [20/100], Loss: 0.8990, Train Accuracy: 0.4714\n",
            "Test Accuracy: 0.4451\n",
            "Epoch [21/100], Loss: 0.8831, Train Accuracy: 0.4714\n",
            "Test Accuracy: 0.4417\n",
            "Epoch [22/100], Loss: 0.8663, Train Accuracy: 0.4663\n",
            "Test Accuracy: 0.4562\n",
            "Epoch [23/100], Loss: 0.8558, Train Accuracy: 0.4853\n",
            "Test Accuracy: 0.4528\n",
            "Epoch [24/100], Loss: 0.8569, Train Accuracy: 0.4739\n",
            "Test Accuracy: 0.4628\n",
            "Epoch [25/100], Loss: 0.8470, Train Accuracy: 0.4738\n",
            "Test Accuracy: 0.4606\n",
            "Epoch [26/100], Loss: 0.8301, Train Accuracy: 0.4807\n",
            "Test Accuracy: 0.4384\n",
            "Epoch [27/100], Loss: 0.8273, Train Accuracy: 0.4757\n",
            "Test Accuracy: 0.4395\n",
            "Epoch [28/100], Loss: 0.8217, Train Accuracy: 0.4850\n",
            "Test Accuracy: 0.4362\n",
            "Epoch [29/100], Loss: 0.8185, Train Accuracy: 0.4764\n",
            "Test Accuracy: 0.4428\n",
            "Epoch [30/100], Loss: 0.8166, Train Accuracy: 0.4773\n",
            "Test Accuracy: 0.4451\n",
            "Epoch [31/100], Loss: 0.8107, Train Accuracy: 0.4890\n",
            "Test Accuracy: 0.4584\n",
            "Epoch [32/100], Loss: 0.8029, Train Accuracy: 0.4850\n",
            "Test Accuracy: 0.4595\n",
            "Epoch [33/100], Loss: 0.7958, Train Accuracy: 0.4780\n",
            "Test Accuracy: 0.4728\n",
            "Epoch [34/100], Loss: 0.7899, Train Accuracy: 0.4911\n",
            "Test Accuracy: 0.4473\n",
            "Epoch [35/100], Loss: 0.7846, Train Accuracy: 0.4860\n",
            "Test Accuracy: 0.4539\n",
            "Epoch [36/100], Loss: 0.7812, Train Accuracy: 0.4807\n",
            "Test Accuracy: 0.4695\n",
            "Epoch [37/100], Loss: 0.7797, Train Accuracy: 0.4946\n",
            "Test Accuracy: 0.4351\n",
            "Epoch [38/100], Loss: 0.7851, Train Accuracy: 0.4869\n",
            "Test Accuracy: 0.4661\n",
            "Epoch [39/100], Loss: 0.7848, Train Accuracy: 0.4939\n",
            "Test Accuracy: 0.4539\n",
            "Epoch [40/100], Loss: 0.7778, Train Accuracy: 0.4970\n",
            "Test Accuracy: 0.4606\n",
            "Epoch [41/100], Loss: 0.7777, Train Accuracy: 0.4920\n",
            "Test Accuracy: 0.4562\n",
            "Epoch [42/100], Loss: 0.7722, Train Accuracy: 0.5013\n",
            "Test Accuracy: 0.4506\n",
            "Epoch [43/100], Loss: 0.7753, Train Accuracy: 0.4939\n",
            "Test Accuracy: 0.4573\n",
            "Epoch [44/100], Loss: 0.7677, Train Accuracy: 0.4867\n",
            "Test Accuracy: 0.4550\n",
            "Epoch [45/100], Loss: 0.7658, Train Accuracy: 0.4983\n",
            "Test Accuracy: 0.4384\n",
            "Epoch [46/100], Loss: 0.7612, Train Accuracy: 0.4983\n",
            "Test Accuracy: 0.4539\n",
            "Epoch [47/100], Loss: 0.7573, Train Accuracy: 0.4870\n",
            "Test Accuracy: 0.4506\n",
            "Epoch [48/100], Loss: 0.7627, Train Accuracy: 0.4977\n",
            "Test Accuracy: 0.4628\n",
            "Epoch [49/100], Loss: 0.7770, Train Accuracy: 0.4958\n",
            "Test Accuracy: 0.4673\n",
            "Epoch [50/100], Loss: 0.7668, Train Accuracy: 0.4944\n",
            "Test Accuracy: 0.4595\n",
            "Epoch [51/100], Loss: 0.7604, Train Accuracy: 0.4976\n",
            "Test Accuracy: 0.4351\n",
            "Epoch [52/100], Loss: 0.7567, Train Accuracy: 0.5041\n",
            "Test Accuracy: 0.4573\n",
            "Epoch [53/100], Loss: 0.7561, Train Accuracy: 0.4993\n",
            "Test Accuracy: 0.4606\n",
            "Epoch [54/100], Loss: 0.7539, Train Accuracy: 0.4928\n",
            "Test Accuracy: 0.4650\n",
            "Epoch [55/100], Loss: 0.7491, Train Accuracy: 0.5059\n",
            "Test Accuracy: 0.4440\n",
            "Epoch [56/100], Loss: 0.7489, Train Accuracy: 0.5021\n",
            "Test Accuracy: 0.4695\n",
            "Epoch [57/100], Loss: 0.7526, Train Accuracy: 0.5051\n",
            "Test Accuracy: 0.4584\n",
            "Epoch [58/100], Loss: 0.7615, Train Accuracy: 0.4965\n",
            "Test Accuracy: 0.4595\n",
            "Epoch [59/100], Loss: 0.7624, Train Accuracy: 0.4963\n",
            "Test Accuracy: 0.4673\n",
            "Epoch [60/100], Loss: 0.7580, Train Accuracy: 0.5008\n",
            "Test Accuracy: 0.4473\n",
            "Epoch [61/100], Loss: 0.7608, Train Accuracy: 0.5007\n",
            "Test Accuracy: 0.4728\n",
            "Epoch [62/100], Loss: 0.7560, Train Accuracy: 0.4982\n",
            "Test Accuracy: 0.4573\n",
            "Epoch [63/100], Loss: 0.7517, Train Accuracy: 0.5071\n",
            "Test Accuracy: 0.4673\n",
            "Epoch [64/100], Loss: 0.7662, Train Accuracy: 0.5016\n",
            "Test Accuracy: 0.4661\n",
            "Epoch [65/100], Loss: 0.7575, Train Accuracy: 0.5024\n",
            "Test Accuracy: 0.4351\n",
            "Epoch [66/100], Loss: 0.7640, Train Accuracy: 0.5080\n",
            "Test Accuracy: 0.4717\n",
            "Epoch [67/100], Loss: 0.7542, Train Accuracy: 0.4984\n",
            "Test Accuracy: 0.4528\n",
            "Epoch [68/100], Loss: 0.7461, Train Accuracy: 0.4945\n",
            "Test Accuracy: 0.4550\n",
            "Epoch [69/100], Loss: 0.7432, Train Accuracy: 0.5007\n",
            "Test Accuracy: 0.4506\n",
            "Epoch [70/100], Loss: 0.7503, Train Accuracy: 0.4970\n",
            "Test Accuracy: 0.4628\n",
            "Epoch [71/100], Loss: 0.7412, Train Accuracy: 0.5048\n",
            "Test Accuracy: 0.4206\n",
            "Epoch [72/100], Loss: 0.7422, Train Accuracy: 0.4979\n",
            "Test Accuracy: 0.4440\n",
            "Epoch [73/100], Loss: 0.7383, Train Accuracy: 0.5024\n",
            "Test Accuracy: 0.4728\n",
            "Epoch [74/100], Loss: 0.7393, Train Accuracy: 0.4913\n",
            "Test Accuracy: 0.4661\n",
            "Epoch [75/100], Loss: 0.7354, Train Accuracy: 0.5083\n",
            "Test Accuracy: 0.4062\n",
            "Epoch [76/100], Loss: 0.7351, Train Accuracy: 0.5063\n",
            "Test Accuracy: 0.4495\n",
            "Epoch [77/100], Loss: 0.7394, Train Accuracy: 0.5039\n",
            "Test Accuracy: 0.4628\n",
            "Epoch [78/100], Loss: 0.7418, Train Accuracy: 0.5083\n",
            "Test Accuracy: 0.4440\n",
            "Epoch [79/100], Loss: 0.7439, Train Accuracy: 0.5068\n",
            "Test Accuracy: 0.4562\n",
            "Epoch [80/100], Loss: 0.7398, Train Accuracy: 0.5069\n",
            "Test Accuracy: 0.4595\n",
            "Epoch [81/100], Loss: 0.7379, Train Accuracy: 0.5061\n",
            "Test Accuracy: 0.4506\n",
            "Epoch [82/100], Loss: 0.7365, Train Accuracy: 0.4970\n",
            "Test Accuracy: 0.4317\n",
            "Epoch [83/100], Loss: 0.7325, Train Accuracy: 0.5076\n",
            "Test Accuracy: 0.4539\n",
            "Epoch [84/100], Loss: 0.7336, Train Accuracy: 0.5030\n",
            "Test Accuracy: 0.4617\n",
            "Epoch [85/100], Loss: 0.7375, Train Accuracy: 0.5083\n",
            "Test Accuracy: 0.4650\n",
            "Epoch [86/100], Loss: 0.7408, Train Accuracy: 0.5049\n",
            "Test Accuracy: 0.4606\n",
            "Epoch [87/100], Loss: 0.7356, Train Accuracy: 0.5069\n",
            "Test Accuracy: 0.4406\n",
            "Epoch [88/100], Loss: 0.7351, Train Accuracy: 0.5075\n",
            "Test Accuracy: 0.4417\n",
            "Epoch [89/100], Loss: 0.7345, Train Accuracy: 0.5042\n",
            "Test Accuracy: 0.4717\n",
            "Epoch [90/100], Loss: 0.7311, Train Accuracy: 0.5128\n",
            "Test Accuracy: 0.4639\n",
            "Epoch [91/100], Loss: 0.7294, Train Accuracy: 0.5027\n",
            "Test Accuracy: 0.4440\n",
            "Epoch [92/100], Loss: 0.7394, Train Accuracy: 0.5051\n",
            "Test Accuracy: 0.4606\n",
            "Epoch [93/100], Loss: 0.7420, Train Accuracy: 0.4997\n",
            "Test Accuracy: 0.4295\n",
            "Epoch [94/100], Loss: 0.7368, Train Accuracy: 0.5066\n",
            "Test Accuracy: 0.4550\n",
            "Epoch [95/100], Loss: 0.7360, Train Accuracy: 0.5063\n",
            "Test Accuracy: 0.4473\n",
            "Epoch [96/100], Loss: 0.7503, Train Accuracy: 0.5055\n",
            "Test Accuracy: 0.4451\n",
            "Epoch [97/100], Loss: 0.7521, Train Accuracy: 0.5083\n",
            "Test Accuracy: 0.4473\n",
            "Epoch [98/100], Loss: 0.7471, Train Accuracy: 0.4986\n",
            "Test Accuracy: 0.4573\n",
            "Epoch [99/100], Loss: 0.7377, Train Accuracy: 0.5059\n",
            "Test Accuracy: 0.4440\n",
            "Epoch [100/100], Loss: 0.7399, Train Accuracy: 0.5124\n",
            "Test Accuracy: 0.4506\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the model and define training parameters\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BiLSTMClassifier(\n",
        "    emb_dim, 128, len(vocab), len(label_encoder.classes_), emb_table\n",
        ").to(device)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model and evaluate its performance on the test set after each epoch\n",
        "number_epochs = 100\n",
        "for epoch in range(number_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for sentences, labels in train_loader:\n",
        "        sentences, labels = sentences.to(device), labels.to(device)\n",
        "        outputs = model(sentences)\n",
        "        loss = loss_function(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "    train_accuracy = total_correct / total_samples\n",
        "    print(\n",
        "        f\"Epoch [{epoch+1}/{number_epochs}], Loss: {total_loss/len(train_loader):.4f}, Train Accuracy: {train_accuracy:.4f}\"\n",
        "    )\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    model.eval()\n",
        "    total_test_correct = 0\n",
        "    total_test_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for sentences, labels in test_loader:\n",
        "            sentences, labels = sentences.to(device), labels.to(device)\n",
        "            outputs = model(sentences)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_test_correct += (predicted == labels).sum().item()\n",
        "            total_test_samples += labels.size(0)\n",
        "\n",
        "    test_accuracy = total_test_correct / total_test_samples\n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8A23WZK2V6r"
      },
      "source": [
        "Lei的bilstm根据gpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Bji4AX6a-a3",
        "outputId": "9f635cad-43bf-4096-d43a-983957bda70c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "Training Accuracy: 0.6340\n",
            "Validation Accuracy: 0.6419\n",
            "Epoch 2/10\n",
            "Training Accuracy: 0.6543\n",
            "Validation Accuracy: 0.6318\n",
            "Epoch 3/10\n",
            "Training Accuracy: 0.6577\n",
            "Validation Accuracy: 0.6385\n",
            "Epoch 4/10\n",
            "Training Accuracy: 0.6650\n",
            "Validation Accuracy: 0.6622\n",
            "Epoch 5/10\n",
            "Training Accuracy: 0.6800\n",
            "Validation Accuracy: 0.6644\n",
            "Epoch 6/10\n",
            "Training Accuracy: 0.6935\n",
            "Validation Accuracy: 0.6712\n",
            "Epoch 7/10\n",
            "Training Accuracy: 0.6952\n",
            "Validation Accuracy: 0.6836\n",
            "Epoch 8/10\n",
            "Training Accuracy: 0.6999\n",
            "Validation Accuracy: 0.6881\n",
            "Epoch 9/10\n",
            "Training Accuracy: 0.7154\n",
            "Validation Accuracy: 0.6881\n",
            "Epoch 10/10\n",
            "Training Accuracy: 0.7181\n",
            "Validation Accuracy: 0.6892\n",
            "Test Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.62      0.65       263\n",
            "           1       0.70      0.84      0.76       393\n",
            "           2       0.61      0.49      0.54       245\n",
            "\n",
            "    accuracy                           0.68       901\n",
            "   macro avg       0.67      0.65      0.65       901\n",
            "weighted avg       0.67      0.68      0.67       901\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# First we need to convert the label in string format into an integer\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(\n",
        "    y_train\n",
        ")  # Fit label encoder and return encoded labels\n",
        "y_val_encoded = label_encoder.transform(y_val)  # Transform labels to encoded version\n",
        "y_test_encoded = label_encoder.transform(y_test)  # Transform labels to encoded version\n",
        "\n",
        "# Convert numpy arrays to torch tensors\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32).unsqueeze(\n",
        "    1\n",
        ")  # Add sequence length dimension\n",
        "y_train_t = torch.tensor(y_train_encoded, dtype=torch.long)\n",
        "X_val_t = torch.tensor(X_val, dtype=torch.float32).unsqueeze(1)\n",
        "y_val_t = torch.tensor(y_val_encoded, dtype=torch.long)\n",
        "X_test_t = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)\n",
        "y_test_t = torch.tensor(y_test_encoded, dtype=torch.long)\n",
        "\n",
        "# Create Tensor datasets\n",
        "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
        "val_dataset = TensorDataset(X_val_t, y_val_t)\n",
        "test_dataset = TensorDataset(X_test_t, y_test_t)\n",
        "\n",
        "# Define DataLoaders\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "# Define the BiLSTM Model\n",
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, num_layers, output_dim):\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(\n",
        "            embedding_dim,\n",
        "            hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            bidirectional=True,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initial states\n",
        "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_dim).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_dim).to(x.device)\n",
        "        # Forward propagate LSTM\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        # Select last time step's output\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "\n",
        "# Model initialization\n",
        "embedding_dim = X_train.shape[1]  # Number of features\n",
        "hidden_dim = 128\n",
        "num_layers = 2\n",
        "output_dim = len(set(y_train_encoded))  # Number of unique labels\n",
        "\n",
        "model = BiLSTM(embedding_dim, hidden_dim, num_layers, output_dim).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, data_loader):\n",
        "    model.eval()\n",
        "    true_labels, predicted_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "            predicted_labels.extend(predicted.cpu().numpy())\n",
        "    return true_labels, predicted_labels\n",
        "\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluate the model\n",
        "    train_true, train_preds = evaluate_model(model, train_loader)\n",
        "    val_true, val_preds = evaluate_model(model, val_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "    print(f\"Training Accuracy: {accuracy_score(train_true, train_preds):.4f}\")\n",
        "    print(f\"Validation Accuracy: {accuracy_score(val_true, val_preds):.4f}\")\n",
        "\n",
        "# Evaluate on test data\n",
        "test_true, test_preds = evaluate_model(model, test_loader)\n",
        "print(\"Test Performance:\")\n",
        "print(classification_report(test_true, test_preds))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
